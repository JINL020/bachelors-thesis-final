{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Paths and Other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobilenet'\n",
    "\n",
    "WORKSPACE_PATH = os.path.join('..\\\\', '02_Workspace')\n",
    "IMAGE_PATH: os.path.join(WORKSPACE_PATH,'images')\n",
    "SAVED_MODEL_PATH: os.path.join(WORKSPACE_PATH,'models', CUSTOM_MODEL_NAME, 'export', 'saved_model')\n",
    "\n",
    "LABELMAP_FILE = os.path.join(WORKSPACE_PATH, 'annotations', 'label_map.pbtxt'),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent GPU complete consumption\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RunTimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SavedModel\n",
    "model = tf.saved_model.load(SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detect from an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input \n",
    "# IMAGE_PATH = os.path.join(IMAGE_PATH, 'Autos', '20230913_210950.jpg')\n",
    "# IMAGE_PATH = os.path.join(IMAGE_PATH, 'test', 'sonder_3.jpg')\n",
    "# IMAGE_PATH = os.path.join(IMAGE_PATH, 'test', 'bgld_1.jpg')\n",
    "\n",
    "DIR_PATH = os.path.join(IMAGE_PATH, 'test')\n",
    "\n",
    "for filename in os.listdir(DIR_PATH):\n",
    "    if filename.endswith('.jpg'): \n",
    "        file_path = os.path.join(DIR_PATH, filename)\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # Perform inference\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0).astype(np.uint8))\n",
    "        detections = model(input_tensor)\n",
    "\n",
    "        # Remove extra dim from array\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections   \n",
    "\n",
    "        # Extract information from the detections\n",
    "        boxes = detections['detection_boxes']\n",
    "        classes = detections['detection_classes'].astype(int)\n",
    "        scores = detections['detection_scores']\n",
    "\n",
    "        # Visualize the results\n",
    "        image_np_with_detections = image_np.copy()\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np_with_detections,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    max_boxes_to_draw=2,\n",
    "                    min_score_thresh=.5,\n",
    "                    agnostic_mode=False)\n",
    "\n",
    "        # Convert to PIL image\n",
    "        # h, w, _ = image_np_with_detections.shape\n",
    "        image_pil = Image.fromarray(image_np_with_detections)\n",
    "\n",
    "        # display(image_pil)\n",
    "        # resized_image = image_pil.resize((int(w/8), int(h/8)))\n",
    "        # display(resized_image)\n",
    "\n",
    "\n",
    "        # Save inference\n",
    "        SAVE_PATH = os.path.join(IMAGE_PATH, 'test-result', filename)\n",
    "        image_pil.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Real Time Detections from your Webcam or Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_threshold = 0.1\n",
    "detection_threshold = 0.6\n",
    "\n",
    "# VIDEO_PATH = os.path.join(IMAGE_PATH, 'Autos', '20231106_222316.mp4')\n",
    "# cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Preprocess input \n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    # Perform inference\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0).astype(np.uint8))\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    # Remove extra dim from array\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections   \n",
    "    \n",
    "    # Extract information from the detections\n",
    "    scores = detections['detection_scores']\n",
    "    boxes = detections['detection_boxes']\n",
    "    classes = detections['detection_classes'].astype(int)\n",
    "\n",
    "    # Visualize the results\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                boxes,\n",
    "                classes,\n",
    "                scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=1,\n",
    "                min_score_thresh=detection_threshold,\n",
    "                agnostic_mode=False)\n",
    "    \n",
    "    try: \n",
    "        text, region = ocr(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    h, w, _ = image_np_with_detections.shape\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (w, h)))\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        print(\"Exit program.\")\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
